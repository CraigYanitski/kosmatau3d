{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "441574bc-15ac-4e31-8b51-70939daa153d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Clumpy ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa2c33-d507-4f34-84bf-87739b8c8a22",
   "metadata": {
    "tags": []
   },
   "source": [
    "The method utilised in `kosmatau3d` to simulate a clumpy ISM with velocity dispersion $\\sigma_{ens}$ in a voxel is to use a fractal ensemble, that is, to use many smaller self-similar clumps with intrinsic velocity dispersion $\\sigma_{cl}$. Each clump thus also contributes to the emissivity and opacity at each observing velocity. The discretisation is shown below.\n",
    "\n",
    "$$\n",
    "\\Delta N_{j,i} \\equiv \\frac{N_j}{\\sqrt{2 \\pi \\sigma_{ens}^2}} \\mathrm{exp} \\left( -\\frac{(v_{vox} - v_i)^2}{2\\sigma_{ens}^2} \\right) \\delta v_j,\n",
    "$$\n",
    "\n",
    "where $j$ refers to a particular clump mass, $i$ refers to the velocity of the clump, and $vox$ refers to the average value for the voxel (so a voxel with $v_{vox} = 0$ would have a Gaussian velocity distribution centered at 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e3dd0d-5033-477d-89f8-7c566e6bbd47",
   "metadata": {},
   "source": [
    "Each clump has an emissivity and opacity that follow Gaussian distributions with velocity dispersion $\\sigma_{cl}$. Thus the clumps at one systematic velocity will contribute distributions to the emissivity and opacity depending on the observing velocity:\n",
    "\n",
    "$$\n",
    "\\epsilon_{ens, i} (v_{obs}), \\kappa_{ens, i} (v_{obs}) \\propto \\mathrm{exp} \\left( - \\frac{(v_{i} - v_{obs})^2}{2 \\sigma_{cl}^2} \\right).\n",
    "$$\n",
    "\n",
    "This results in the final emissivity and opacity of the ensemble depending on two Gaussian distributions,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\big\\{ \\epsilon_{ens} (v_{obs}), \\kappa_{ens} (v_{obs}) \\big\\} =& \\sum_i exp \\left( -\\frac{(v_{obs}-v_i)^2}{2 \\sigma_{cl}^2} \\right) \\sum_j \\Delta N_{j,i} \\big\\{ \\epsilon_{j}, \\kappa_{j} \\big\\}, \\\\\n",
    "\\big\\{ \\epsilon_{ens} (v_{obs}), \\kappa_{ens} (v_{obs}) \\big\\} =& \\frac{1}{\\sqrt{2 \\pi \\sigma_{ens}^2}} \\sum_i exp \\left( -\\frac{(v_{obs}-v_i)^2}{2 \\sigma_{cl}^2} \\right) \\sum_j N_{j} \\big\\{ \\epsilon_{j}, \\kappa_{j} \\big\\} exp \\left( -\\frac{(v_{vox}-v_i)^2}{2 \\sigma_{ens}^2} \\right),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Due to the two distributions that contribute to the ensemble emissivity and opacity, the final distributions will have a larger effective velocity dispersion:\n",
    "\n",
    "$$\n",
    "\\sigma_{ens, eff} \\equiv \\sqrt{\\sigma_{ens}^2 + \\sigma_{cl}^2}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193fee21-fb38-4daf-b7e8-7bc3368c7e34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from copy import copy\n",
    "from scipy import stats  # noqa\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a40df8-0bf3-4222-b3c2-64346faabf2b",
   "metadata": {},
   "source": [
    "## Example parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba46d057-0a1a-4807-882e-269bb0110325",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensemble properties\n",
    "#  ens_test is a flag that can be set to test ensembles of two clump sizes\n",
    "ens_test = False\n",
    "\n",
    "if ens_test:\n",
    "    n_j = [10, 50]  # Using [5, 100] gives a very strange result\n",
    "    eps_j = [10, 1]\n",
    "    kap_j = [1.5, 0.5]\n",
    "    r_j = [0.5, 0.1]\n",
    "else:\n",
    "    n_j = [10]\n",
    "    eps_j = [10]\n",
    "    kap_j = [1.5]\n",
    "    r_j = [0.5]\n",
    "\n",
    "sigma_cl = 0.71\n",
    "sigma_ens = 2\n",
    "sigma_ens_tot = np.linalg.norm((sigma_cl, sigma_ens))\n",
    "n_gauss = 6\n",
    "n_v = 10\n",
    "v_vox = 0\n",
    "ds = 1\n",
    "nmax = 0\n",
    "\n",
    "# Debugging flags\n",
    "old_computation = False\n",
    "incorrect_computation = False\n",
    "test_opacity = False\n",
    "approx = False\n",
    "plot_all = True\n",
    "\n",
    "# Most recent solution (independant of the internal velocity grid)\n",
    "suggested_fix = True\n",
    "\n",
    "# Plot settings\n",
    "mpl.rcParams['text.usetex'] = True\n",
    "figsize = (7, 7)\n",
    "fontsize = 24\n",
    "legend_factor = 3/6\n",
    "\n",
    "# Plotting kwargs\n",
    "approximated_kwargs = {'label': r'approximated with $N_j$',\n",
    "                       'ls': '-',\n",
    "                       'lw': 4,\n",
    "                       'c': 'xkcd:black',\n",
    "                       }\n",
    "calculated_kwargs = {\n",
    "                     'label': r'calculated using $N_{j, i}$',\n",
    "                     'ls': '-',\n",
    "                     'lw': 3,\n",
    "                     'c': 'xkcd:gold',\n",
    "                     }\n",
    "fitted_kwargs = {\n",
    "                 'label': r'fitted using $N_{j, i}$',\n",
    "                 'ls': '--',\n",
    "                 'lw': 2,\n",
    "                 'c': 'xkcd:sapphire',\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3689940-7fda-4cd3-a4df-7cabb07c5eb7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "md(r'Below we will examine how this discretisation functions for and ensemble with $\\sigma_{ens} =$'\n",
    "   + '{}'.format(sigma_ens) + r'$\\frac{km}{s}$ and ' + '{}'.format(n_j) + r' clumps, each with $\\sigma_{cl} =$'\n",
    "   + '{}'.format(sigma_cl) + r'$\\frac{km}{s}$, $\\epsilon_\\nu =$'\n",
    "   + '{}'.format(eps_j) + r'$\\frac{K}{pc}$, $\\kappa_\\nu =$'\n",
    "   + '{}'.format(kap_j) + r'$\\frac{1}{pc}$, and a line-of-sight depth of $\\Delta s =$'\n",
    "   + '{}'.format(ds) + r'$pc$. The effective velocity dispersion of the ensemble is thus $\\sigma_{ens, eff} =$'\n",
    "   + '{:.2f}'.format(sigma_ens_tot) + r'$\\frac{km}{s}$. This should be enough to cause absorption features.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681936dc-0538-40c3-9d50-e13f1714ae23",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98bb0de-0acc-414c-a19b-2446ec3881a1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Clump number $\\Delta N_{j, i} \\delta v$ function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d9a263-b1b3-4da7-8998-3e3a03f69436",
   "metadata": {},
   "source": [
    "This is a function to compute the discretisation of the clumps with respect to the internal velocity dispersion. Note that *discrete* values should be of type integer, whereas the output of this function is of type float.\n",
    "\n",
    " - `n_j`: argument for the total number of clumps in the ensemble. This can be a single number for an ensemble of one clumps size or it can be a list for an ensemble of multiple clump types. In the latter case it is assumed that the largest clump is first.\n",
    " - `sigma_ens`: argument for the internal velocity dispersion of the clumps. Note that this must be of type float or int, and must not include the contribution of the intrinsic clump velocity dispersion.\n",
    " - `sigma_cl`: kwarg for the intrinsic clump velocity dispersion. It must be of type float or int. The default value is 0.71.\n",
    " - `v_i`: kwarg for the internal velocity array. Must be of type ndarray, otherwise the array is created (errors still exist in this). The default value is None.\n",
    " - `n_v`: kwarg to adjust the step size in the internal velocity grid, which is the minimum of $\\left( \\frac{\\sigma_{ens}}{n_v}, \\frac{\\sigma_{cl}}{n_v} \\right)$. The default is 1.\n",
    " - `v_vox`: kwarg to set the average velocity of the ensemble. The default is 0 km/s.\n",
    " - `n_gauss`: kwarg to adjust how many standard deviations are calculated in the discretisation. The default is 4, making the approximation >99% accurate.\n",
    " - `suggested_fix`: flag to set whether the original calculation of $\\Delta N_j$ is returned or the suggested improvement of $\\frac{dN_j}{dv}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f9c65b-7868-4419-bb63-0a1b20ccaa43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def delta_n_ji_dv(n_j, sigma_ens, sigma_cl=0.71, v_i=None, n_v=None, v_vox=0, n_gauss=4, suggested_fix=False):\n",
    "\n",
    "    if not n_v:\n",
    "        n_v = 1\n",
    "        \n",
    "    if isinstance(v_i, np.ndarray):\n",
    "        dv = v_i[1]-v_i[0]\n",
    "    else:\n",
    "        dv = np.minimum(sigma_ens/n_v, sigma_cl/n_v)\n",
    "        v_i = np.linspace(np.floor(-n_gauss*sigma_ens), np.ceil(n_gauss*sigma_ens), num=int(np.round(2*n_gauss*sigma_ens/dv))+1)\n",
    "    \n",
    "    if isinstance(n_j, int) or isinstance(n_j, float):\n",
    "        n_j = np.asarray([[n_j]])\n",
    "    elif isinstance(n_j, list):\n",
    "        n_j = np.asarray(n_j)\n",
    "    if n_j.ndim == 1:\n",
    "        n_j = np.asarray([n_j]).reshape(-1, 1)\n",
    "        \n",
    "    if suggested_fix:\n",
    "        suggested_factor = np.sqrt(2*np.pi*sigma_cl**2) / np.sqrt(2*np.pi*sigma_ens_tot**2) * np.exp(-(v_vox-v_i)**2/2/sigma_ens_tot**2)\n",
    "    else:\n",
    "        suggested_factor = 1 / np.sqrt(2*np.pi*sigma_ens**2) * np.exp(-(v_vox-v_i)**2/2/sigma_ens**2) * dv\n",
    "    \n",
    "    delta_n_dv = np.asarray([n * suggested_factor for n in n_j])\n",
    "    # delta_n = delta_n * (n_j / delta_n.sum()) / dv\n",
    "    \n",
    "    return delta_n_dv, v_i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ab15a-4d53-44b1-a7d0-c72ddf51d382",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Probability $p_{j, i}$ function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed61f838-fe47-4054-ad71-e6b1828dbbbb",
   "metadata": {},
   "source": [
    "Function to convert the clump number discretisation to combinations $k_{j,i}$ at each internal velocity, then calculate the probability of observing each combination $p_{j,i} \\equiv p(k_{j,i})$.\n",
    "\n",
    " - `r_cl`: argument for the radius of each clump in the ensemble. It can be of type int or float for an ensemble of one clump type, or a list for an ensemble of multiple clump types.\n",
    " - `ds`: kwarg for the scale of the voxel. The default is 1.\n",
    " - `delta_n_ji`: kwarg for the discretised number array. The default is 1.\n",
    " - `poisson`: if True, use the Poisson distribution to calculate the probabilities. Otherwise use the binomial distribution. The default is False.\n",
    " - `nmax`: kwarg used to normalise the discretised numbers. The default is defined in the beginning of the notebook.\n",
    " - `debug`: if True, print debugging comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba857e84-4043-4143-bc45-495b2edf40c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def probability(r_cl, ds=1, delta_n_ji=1, poisson=False, nmax=nmax, debug=False):\n",
    "\n",
    "    if isinstance(r_cl, int) or isinstance(r_cl, float):\n",
    "        r_cl = np.asarray([[r_cl]])\n",
    "    elif isinstance(r_cl, list):\n",
    "        r_cl = np.asarray(r_cl)\n",
    "    if r_cl.ndim == 1:\n",
    "        r_cl = np.asarray([r_cl]).reshape(-1, 1)\n",
    "\n",
    "    if isinstance(delta_n_ji, int) or isinstance(delta_n_ji, float):\n",
    "        delta_n_ji = np.asarray([[delta_n_ji]])\n",
    "    elif isinstance(delta_n_ji, list):\n",
    "        delta_n_ji = np.asarray(delta_n_ji)\n",
    "    if delta_n_ji.ndim == 1:\n",
    "        delta_n_ji = np.asarray([delta_n_ji])\n",
    "\n",
    "    p_j = np.pi*r_cl**2/ds**2\n",
    "\n",
    "    if nmax:\n",
    "        factor = np.asarray([[nmax / delta_n_ji[0, i]\n",
    "                              for i in range(delta_n_ji.shape[1])]\n",
    "                             for cl in range(delta_n_ji.shape[0])])\n",
    "    else:\n",
    "        factor = np.asarray([[np.maximum(1, np.round(delta_n_ji[0, i])) / delta_n_ji[0, i]\n",
    "                              for i in range(delta_n_ji.shape[1])]\n",
    "                             for cl in range(delta_n_ji.shape[0])])\n",
    "\n",
    "    p_scaled = p_j[0]/factor[0]\n",
    "    # print(p_scaled)\n",
    "    thresh = 0.95\n",
    "    i_change = p_scaled > thresh\n",
    "    # print(i_change, factor, p_j/factor)\n",
    "    if i_change.any() or np.isnan(p_scaled).any():\n",
    "        n_temp = np.ceil(delta_n_ji[:, i_change] * thresh*p_j[0]/factor[0][i_change])\n",
    "        factor[:, i_change] = n_temp/delta_n_ji[:, i_change]\n",
    "\n",
    "    if debug:\n",
    "        print(delta_n_ji*factor)\n",
    "\n",
    "    k_ji_list = [[np.arange(np.round(delta_n_ji[cl, i]*factor[cl, i]) + 1, dtype=int)\n",
    "                  for cl in range(delta_n_ji.shape[0])]\n",
    "                 for i in range(delta_n_ji.shape[1])]\n",
    "\n",
    "    k_ji = np.asarray([[k.flatten() for k in np.meshgrid(*k_ji_list[i])]\n",
    "                       for i in range(len(k_ji_list))], dtype=object)\n",
    "    \n",
    "    # for _ in range(p_scaled.size):\n",
    "    #     print('{:.6f} {:.6f} {} {} {}'.format(p_scaled[_], factor[0, _], i_change[_], np.round(delta_n_ji[0, _]*factor[0, _]), k_ji_list[_][0]))\n",
    "\n",
    "    if poisson:\n",
    "        p_ji = np.asarray([[stats.poisson.pmf(k_ji[i, cl].astype(int),\n",
    "                                              delta_n_ji[cl, i]*p_j[cl, 0])\n",
    "                            for i in range(delta_n_ji.shape[1])]\n",
    "                           for cl in range(delta_n_ji.shape[0])], dtype=object)\n",
    "    else:\n",
    "        p_ji = np.asarray([[stats.binom.pmf(k_ji[i, cl].astype(int),\n",
    "                                            np.round(delta_n_ji[cl, i]*factor[cl, i]),\n",
    "                                            p_j[cl, 0]/factor[cl, i])\n",
    "                            for i in range(delta_n_ji.shape[1])]\n",
    "                           for cl in range(delta_n_ji.shape[0])], dtype=object)\n",
    "\n",
    "    return p_ji, np.swapaxes(k_ji, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67891a52-7268-418e-8176-2795f865ce86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Clump number $\\Delta N_{j,i}$ plotting function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478a3894-8335-4266-9c7e-63573da3f583",
   "metadata": {},
   "source": [
    "Function to calculate and plot the clump number discretisation. The total mass is also printed.\n",
    "\n",
    " - `v_i`: kwarg for the internal velocity array. Must be of type ndarray, otherwise the array is created (errors still exist in this). The default value is None.\n",
    " - `n_v`: kwarg to adjust the step size in the internal velocity grid, which is the minimum of $\\left( \\frac{\\sigma_{ens}}{n_v}, \\frac{\\sigma_{cl}}{n_v} \\right)$. The default is 1.\n",
    " - `suggested_fix`: flag to set whether the original calculation of $\\Delta N_j$ is returned or the suggested improvement of $\\frac{dN_j}{dv}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ad5ad-13ce-4a05-842c-453b98383326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_clump_number(v_i=None, n_v=n_v, suggested_fix=suggested_fix):\n",
    "    \n",
    "    ensemble_n_dv, v_i = delta_n_ji_dv(n_j, sigma_ens, v_i=v_i, v_vox=v_vox, n_gauss=n_gauss, n_v=n_v, suggested_fix=suggested_fix)\n",
    "    dv = v_i[1]-v_i[0]\n",
    "    print(np.shape(ensemble_n_dv))\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    v = np.linspace(v_vox-10, v_vox+10, num=1000)\n",
    "    dv_obs = v[1]-v[0]\n",
    "    ax.set_xlabel(r'$v_i \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "    if suggested_fix:\n",
    "        n_dist = np.sum([n * np.sqrt(2*np.pi*sigma_cl**2) / np.sqrt(2*np.pi*sigma_ens_tot**2) * np.exp(-(v_vox-v)**2/2/sigma_ens_tot**2) for n in n_j], axis=0)\n",
    "        print('Total Mass (without discretisation): {:.3f} M_sol'.format((n_dist).sum() * dv_obs / np.sqrt(2*np.pi*sigma_cl**2)))\n",
    "        print('Total Mass (with discretisation): {:.3f} M_sol'.format(ensemble_n_dv.sum() * dv / np.sqrt(2*np.pi*sigma_cl**2)))\n",
    "        ax.plot(v, n_dist, label='approximated')\n",
    "        ax.set_ylabel(r'$N_{j,i}$', fontsize=fontsize)\n",
    "    else:\n",
    "        n_dist = np.sum([n / np.sqrt(2*np.pi*sigma_ens**2) * np.exp(-(v_vox-v)**2/2/sigma_ens**2) for n in n_j], axis=0)\n",
    "        print('Total Mass (without discretisation): {:.3f} M_sol'.format((n_dist).sum()*dv_obs))\n",
    "        print('Total Mass (with discretisation): {:.3f} M_sol'.format(ensemble_n_dv.sum()))\n",
    "        ensemble_n_dv /= dv\n",
    "        ax.plot(v, n_dist, label='approximated')\n",
    "        ax.set_ylabel(r'$\\Delta N_{j,i}$', fontsize=fontsize)\n",
    "    ax.step(v_i, ensemble_n_dv.sum(0), where='mid', label='calculated')\n",
    "    ax.legend(fontsize=fontsize*legend_factor)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9364c6ca-818a-4df4-9253-6e7e307afcb6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Emission $\\left( \\left<\\epsilon\\right>_i, \\ \\left<\\kappa\\right>_i, \\ \\left<I\\right>_i \\right)$ plotting function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92b796a-0c58-4e9a-a52b-45dc4d81edb7",
   "metadata": {},
   "source": [
    "Function to calculate and plot the emission from a clumpy ensemble independent of the scale. (ie. Not averaged over a voxel.) The contributions from each internal velocity are also shown. The calculations can be performed in their original implementation or using the more-efficient suggested calculation.\n",
    "\n",
    "The final approximated and calculated integrated intensities are also printed.\n",
    "\n",
    " - `v_i`: kwarg for the internal velocity array. Must be of type ndarray, otherwise the array is created (errors still exist in this). The default value is None.\n",
    " - `n_v`: kwarg to adjust the step size in the internal velocity grid, which is the minimum of $\\left( \\frac{\\sigma_{ens}}{n_v}, \\frac{\\sigma_{cl}}{n_v} \\right)$. The default is defined in the beginning of the notebook.\n",
    " - `suggested_fix`: flag to set whether the original calculation of $\\Delta N_j$ is returned or the suggested improvement of $\\frac{dN_j}{dv}$. The default is defined in the beginning of the notebook.\n",
    " - `kind`: kwarg to set the pass to the interpolation function. This can be *gaussian*, *linear*, *nearest*, *nearest-up*, *zero*, *slinear*, *quadratic*, *cubic*, *previous*, or *next*. 'gaussian' fits a gaussian to the emissivity and optical depth using `scipy.optimize.curve_fit` and the widths are averaged, while the others are passed to `scipy.interpolate.interp1d`. The default is *slinear*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300755ff-f8e6-46df-8392-86091257fe0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_clumpy_emission(v_i=None, n_v=n_v, suggested_fix=suggested_fix, kind='slinear'):\n",
    "    \n",
    "    \n",
    "    # Calculate the Ndv distribution\n",
    "    ensemble_n_dv, v_i = delta_n_ji_dv(n_j, sigma_ens, v_i=v_i, v_vox=v_vox, n_gauss=n_gauss, n_v=n_v, suggested_fix=suggested_fix)\n",
    "    dv = v_i[1]-v_i[0]\n",
    "    \n",
    "    \n",
    "    # Define/adjust the velocity grids as required for the calculations\n",
    "    if suggested_fix:\n",
    "        v_obs = v_vox\n",
    "        v_obs_range = np.linspace(-10, 10, num=1000)\n",
    "    else:\n",
    "        v_obs = np.linspace(-10, 10, num=1000)\n",
    "\n",
    "        \n",
    "    # Emissivity\n",
    "    if suggested_fix:\n",
    "        eps = np.sum([n_j[j]*eps_j[j] * np.sqrt(2*np.pi*sigma_cl**2) / np.sqrt(2*np.pi*sigma_ens_tot**2) * np.exp(-(v_vox-v_obs_range)**2/2/sigma_ens_tot**2) for j in range(len(n_j))], axis=0)\n",
    "        eps_ens = np.zeros_like(v_i)\n",
    "    else:\n",
    "        eps = np.sum([n_j[j]*eps_j[j] * np.sqrt(2*np.pi*sigma_cl**2) / np.sqrt(2*np.pi*sigma_ens_tot**2) * np.exp(-(v_vox-v_obs)**2/2/sigma_ens_tot**2) for j in range(len(n_j))], axis=0)\n",
    "        eps_ens = np.zeros_like(eps)\n",
    "    if plot_all:\n",
    "        eps_fig, eps_ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    \n",
    "    for i, v_cl in enumerate(v_i):\n",
    "        if suggested_fix:\n",
    "            factor = 1\n",
    "        else:\n",
    "            factor = np.exp(-(v_obs-v_cl)**2/2/sigma_cl**2)\n",
    "        \n",
    "        if old_computation:\n",
    "            eps_i = [ensemble_n_dv[j, i]*eps_j[j] * factor for j in range(len(n_j))]\n",
    "        elif incorrect_computation:\n",
    "            eps_i = [ensemble_n_dv[j, i]*eps_j[j]/dv * factor for j in range(len(n_j))]\n",
    "        else:\n",
    "            eps_i = [ensemble_n_dv[j, i]*eps_j[j] * factor for j in range(len(n_j))]\n",
    "        \n",
    "        if plot_all:\n",
    "            eps_ax.plot(v_obs, np.sum(eps_i, axis=0))\n",
    "        \n",
    "        if suggested_fix:\n",
    "            eps_ens[i] = np.sum(eps_i, axis=0)\n",
    "        else:\n",
    "            eps_ens += np.sum(eps_i, axis=0)\n",
    "    \n",
    "    if plot_all:\n",
    "        if suggested_fix:\n",
    "            fn = interp1d(v_i, eps_ens, kind=kind)\n",
    "            eps_fit = fn(v_obs_range)\n",
    "            eps_ax.plot(v_obs_range, eps, **approximated_kwargs)\n",
    "            eps_ax.plot(v_i, eps_ens, **calculated_kwargs)\n",
    "            eps_ax.plot(v_obs_range, eps_fit, **fitted_kwargs)\n",
    "        else:\n",
    "            eps_ax.plot(v_obs, eps, **approximated_kwargs)\n",
    "            eps_ax.plot(v_obs, eps_ens, **calculated_kwargs)\n",
    "        eps_ax.set_xlabel(r'$v_{obs} \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "        eps_ax.set_ylabel(r'$\\epsilon \\ \\left( \\frac{K}{pc} \\right)$', fontsize=fontsize)\n",
    "        eps_ax.legend(fontsize=fontsize*legend_factor)\n",
    "\n",
    "        \n",
    "    # Opacity\n",
    "    if suggested_fix:\n",
    "        kap = np.sum([n_j[j]*kap_j[j] * np.sqrt(2*np.pi*sigma_cl**2) / np.sqrt(2*np.pi*sigma_ens_tot**2) * np.exp(-(v_vox-v_obs_range)**2/2/sigma_ens_tot**2) for j in range(len(n_j))], axis=0)\n",
    "        kap_ens = np.zeros_like(v_i)\n",
    "    else:\n",
    "        kap = np.sum([n_j[j]*kap_j[j] * np.sqrt(2*np.pi*sigma_cl**2) / np.sqrt(2*np.pi*sigma_ens_tot**2) * np.exp(-(v_vox-v_obs)**2/2/sigma_ens_tot**2) for j in range(len(n_j))], axis=0)\n",
    "        kap_ens = np.zeros_like(eps)\n",
    "    if plot_all:\n",
    "        kap_fig, kap_ax = plt.subplots(1, 1, figsize=figsize)\n",
    "        \n",
    "    for i, v_cl in enumerate(v_i):\n",
    "        if suggested_fix:\n",
    "            factor = 1\n",
    "        else:\n",
    "            factor = np.exp(-(v_obs-v_cl)**2/2/sigma_cl**2)\n",
    "            \n",
    "        if old_computation:\n",
    "            kap_i = [ensemble_n_dv[j, i]*kap_j[j] * factor for j in range(len(n_j))]\n",
    "        elif incorrect_computation:\n",
    "            kap_i = [ensemble_n_dv[j, i]*kap_j[j]/dv * factor for j in range(len(n_j))]\n",
    "        else:\n",
    "            kap_i = [ensemble_n_dv[j, i]*kap_j[j] * factor for j in range(len(n_j))]\n",
    "        \n",
    "        if plot_all:\n",
    "            kap_ax.plot(v_obs, np.sum(kap_i, axis=0))\n",
    "        # kap_ens += np.exp(-kap_i*ds)\n",
    "        \n",
    "        if suggested_fix:\n",
    "            kap_ens[i] = np.sum(kap_i, axis=0)\n",
    "        else:\n",
    "            kap_ens += np.sum(kap_i, axis=0)\n",
    "            \n",
    "    # kap_ens = -np.log(kap_ens)/ds\n",
    "    if plot_all:\n",
    "        if suggested_fix:\n",
    "            fn = interp1d(v_i, kap_ens, kind=kind)\n",
    "            kap_fit = fn(v_obs_range)\n",
    "            kap_ax.plot(v_obs_range, kap, **approximated_kwargs)\n",
    "            kap_ax.plot(v_i, kap_ens, **calculated_kwargs)\n",
    "            kap_ax.plot(v_obs_range, kap_fit, **fitted_kwargs)\n",
    "        else:\n",
    "            kap_ax.plot(v_obs, kap, **approximated_kwargs)\n",
    "            kap_ax.plot(v_obs, kap_ens, **calculated_kwargs)\n",
    "        kap_ax.set_xlabel(r'$v_{obs} \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "        kap_ax.set_ylabel(r'$\\kappa \\ \\left( \\frac{1}{pc} \\right)$', fontsize=fontsize)\n",
    "        kap_ax.legend(fontsize=fontsize*legend_factor)\n",
    "\n",
    "        \n",
    "    # Intensity\n",
    "    int_fig, int_ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    intensity = eps/kap * (1-np.exp(-kap*ds))\n",
    "    intensity_ens = eps_ens/kap_ens * (1-np.exp(-kap_ens*ds))\n",
    "    if suggested_fix:\n",
    "        fn = interp1d(v_i, intensity_ens, kind=kind)\n",
    "        intensity_fit = fn(v_obs_range)\n",
    "        int_ax.plot(v_obs_range, intensity, **approximated_kwargs)\n",
    "        int_ax.plot(v_i, intensity_ens, **calculated_kwargs)\n",
    "        int_ax.plot(v_obs_range, intensity_fit, **fitted_kwargs)\n",
    "    else:\n",
    "        int_ax.plot(v_obs, intensity, **approximated_kwargs)\n",
    "        int_ax.plot(v_obs, intensity_ens, **calculated_kwargs)\n",
    "    int_ax.set_xlabel(r'$v_{obs} \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "    int_ax.set_ylabel(r'$\\left< I \\right>_{ens} \\ \\left( K \\right)$', fontsize=fontsize)\n",
    "    int_ax.legend(fontsize=fontsize*legend_factor)\n",
    "\n",
    "    \n",
    "    # Integrated intensity\n",
    "    if suggested_fix:\n",
    "        print('         Integrated intensity (no discretisation):', np.trapz(intensity, v_obs_range))\n",
    "        print('       Integrated intensity (with discretisation):', np.trapz(intensity_ens, v_i))\n",
    "        print('Integrated intensity (fitted with discretisation):', np.trapz(intensity_fit, v_obs_range))\n",
    "    else:\n",
    "        print('Integrated intensity (no discretisation):', np.trapz(intensity, v_obs))\n",
    "        print('Integrated intensity (with discretisation):', np.trapz(intensity_ens, v_obs))\n",
    "    \n",
    "    \n",
    "    # RT equation factor\n",
    "    rt_fig, rt_ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    if suggested_fix:\n",
    "        rt_ax.plot(v_obs_range, eps/kap, **approximated_kwargs)\n",
    "        rt_ax.plot(v_i, eps_ens/kap_ens, **calculated_kwargs)\n",
    "        rt_ax.plot(v_obs_range, eps_fit/kap_fit, **fitted_kwargs)\n",
    "    else:\n",
    "        rt_ax.plot(v_obs, eps/kap, **approximated_kwargs)\n",
    "        rt_ax.plot(v_obs, eps_ens/kap_ens, **calculated_kwargs)\n",
    "    # plt.title(r'Approximated with $N_j$', fontsize=fontsize)\n",
    "    rt_ax.set_xlabel(r'$v_{obs} \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "    rt_ax.set_ylabel(r'$\\frac{\\epsilon}{\\kappa} \\ \\left( K \\right)$', fontsize=fontsize)\n",
    "    rt_ax.legend(fontsize=fontsize*legend_factor)\n",
    "    \n",
    "    # plt.figure(figsize=figsize)\n",
    "    # if suggested_fix:\n",
    "    #     plt.plot(v_i, eps_ens/kap_ens)\n",
    "    # else:\n",
    "    #     plt.plot(v_obs, eps_ens/kap_ens)\n",
    "    # plt.title(r'Calculated using $N_{j, i}$', fontsize=fontsize)\n",
    "    # plt.xlabel(r'$v_{obs} \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "    # plt.ylabel(r'$\\frac{\\left< \\epsilon \\right>_{ens}}{\\left< \\kappa \\right>_{ens}} \\ \\left( K \\right)$', fontsize=fontsize) ;\n",
    "    \n",
    "    return #(eps, eps_ens, kap, kap_ens, intensity, intensity_ens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3894ffd-35d4-463b-a042-ffc0615fe280",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Probabilistic clump number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0853df6-6064-4534-adc5-9fa4af9a0307",
   "metadata": {},
   "source": [
    "Function to plot the number of clumps used in the probabilistic approach. This should follow the emissivity and optical depth curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c491fe-888e-46d2-8712-52a2318c9665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_probabilistic_dNji(v_i=None, v_obs=None, n_v=n_v, suggested_fix=suggested_fix, poisson=False, debug=False):\n",
    "    \n",
    "    # Calculate the clump numbers and combination probabilities\n",
    "    ensemble_n_dv, v_i = delta_n_ji_dv(n_j, sigma_ens, v_i=v_i, v_vox=v_vox, n_gauss=n_gauss, n_v=n_v, suggested_fix=suggested_fix)\n",
    "    dv = v_i[1]-v_i[0]\n",
    "    p_ji, k_ji = probability(r_j, ds=ds, delta_n_ji=ensemble_n_dv, poisson=poisson, debug=debug)\n",
    "    \n",
    "    if isinstance(v_obs, np.ndarray):\n",
    "        pass\n",
    "    else:\n",
    "        v_obs = np.linspace(-10, 10, num=1000)\n",
    "    \n",
    "    for j in range(p_ji.shape[0]):\n",
    "    \n",
    "        dnji = []\n",
    "\n",
    "        for i, v_cl in enumerate(v_i):\n",
    "\n",
    "            p_j = np.array([p_ji[jj, i] for jj in range(p_ji.shape[0])], dtype=float)\n",
    "            k_j = k_ji[j, i]\n",
    "\n",
    "            dnji.append(((p_j.prod(0)/p_j.prod(0).sum()) * k_j).sum())\n",
    "        \n",
    "        a, sigma = curve_fit(gaussian, v_i, dnji, p0=[1, 1])[0]\n",
    "        dn_fit = gaussian(v_obs, a, sigma)\n",
    "        \n",
    "        print('sigma: {:.4f}'.format(sigma))\n",
    "        \n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(v_i, dnji, **calculated_kwargs)\n",
    "        plt.plot(v_obs, dn_fit, **fitted_kwargs)\n",
    "        plt.title('j={}'.format(j), fontsize=fontsize)\n",
    "        plt.xlabel(r'$v_i \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "        if suggested_fix:\n",
    "            plt.ylabel(r'Modified $\\frac{dN_j}{dv}$', fontsize=fontsize)\n",
    "        else:\n",
    "            plt.ylabel(r'$\\Delta N_{ji}$', fontsize=fontsize)\n",
    "        plt.legend(fontsize=fontsize*legend_factor)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6d6a8d-e3bb-4cb5-88c3-dd4abda241a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Probabilistic emission $\\left( \\left<\\tau\\right>_{vox} \\ , \\ \\left<I\\right>_{vox} \\right)$ calculation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4beb41d-e4b1-48d1-8201-ba21c2b87914",
   "metadata": {},
   "source": [
    "Function to calculate the voxel-averaged intensity and optical depth. This can be performed in the original implementation in `kosmatau3d` or using the more-efficient suggested calculation.\n",
    "\n",
    " - `v_i`: kwarg for the internal velocity array. Must be of type ndarray, otherwise the array is created (errors still exist in this). The default value is None.\n",
    " - `v_obs`: kwarg for the observed velocity array. Must be of type ndarray, otherwise the array of size $1000$ is created spanning the interval $\\left[ -10, 10 \\right] \\frac{km}{s}$. The default value is None.\n",
    " - `n_v`: kwarg to adjust the step size in the internal velocity grid, which is the minimum of $\\left( \\frac{\\sigma_{ens}}{n_v}, \\frac{\\sigma_{cl}}{n_v} \\right)$. The default is defined in the beginning of the notebook.\n",
    " - `suggested_fix`: flag to set whether the original calculation of $\\Delta N_j$ is returned or the suggested improvement of $\\frac{dN_j}{dv}$. The default is defined in the beginning of the notebook.\n",
    " - `kind`: kwarg to set the pass to the interpolation function. This can be *gaussian*, *linear*, *nearest*, *nearest-up*, *zero*, *slinear*, *quadratic*, *cubic*, *previous*, or *next*. 'gaussian' fits a gaussian to the emissivity and optical depth using `scipy.optimize.curve_fit` and the widths are averaged, while the others are passed to `scipy.interpolate.interp1d`. The default is *slinear*.\n",
    " - `approx`: kwarg to calculate the approximate emission.\n",
    " - `poisson`: kwarg passed to `probability` to specify if the Poisson distribution should be used over the binomial distribution to calculate the combination probabilities. The default is False, so the binomial distribution is used.\n",
    " - `plotfit`: if True and `kind`='gaussian', the gaussian-fitted emissivity, optical depth, intensity, and source function are calculated with `v_i` and plotted.\n",
    " - `linearfit`: if True and `kind`='gaussian', the gaussian-fitted emissivity and optical depth are interpolated at `v_obs` .\n",
    " - `debug`: print additional debugging statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb1c3f7-d4c8-4681-9b67-33981f7c5f84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_emission(v_i=None, v_obs=None, n_v=n_v, nmax=nmax, suggested_fix=suggested_fix, kind='slinear', approx=approx, poisson=False, \n",
    "                       plotfit=False, linearfit=True, debug=False):\n",
    "\n",
    "    # Calculate the clump numbers and combination probabilities\n",
    "    ensemble_n_dv, v_i = delta_n_ji_dv(n_j, sigma_ens, v_i=v_i, v_vox=v_vox, n_gauss=n_gauss, n_v=n_v, suggested_fix=suggested_fix)\n",
    "    dv = v_i[1]-v_i[0]\n",
    "    p_ji, k_ji = probability(r_j, ds=ds, delta_n_ji=ensemble_n_dv, nmax=nmax, poisson=poisson, debug=debug)\n",
    "    v_obs = np.linspace(-10, 10, num=1000)\n",
    "\n",
    "    # Define/adjust the velocity grids as required for the calculations\n",
    "    if suggested_fix:\n",
    "        if isinstance(v_obs, np.ndarray):\n",
    "            v_obs_range = copy(v_obs)\n",
    "        else:\n",
    "            v_obs_range = np.linspace(-10, 10, num=1000)\n",
    "        v_obs = v_vox\n",
    "    else:\n",
    "        if not isinstance(v_obs, np.ndarray):\n",
    "            v_obs = np.linspace(-10, 10, num=1000)\n",
    "\n",
    "    if suggested_fix:\n",
    "        # eps_ens = np.zeros_like(v_i)\n",
    "        eps_ens = []\n",
    "        kap_ens = []\n",
    "    else:\n",
    "        eps_ens = np.zeros_like(v_obs)\n",
    "        kap_ens = np.zeros_like(v_obs)\n",
    "\n",
    "    # Loop through internal velocities\n",
    "    for i, v_cl in enumerate(v_i):\n",
    "\n",
    "        if suggested_fix:\n",
    "            factor = [(r*4/3) for r in r_j]\n",
    "        else:\n",
    "            factor = [np.exp(-(v_obs-v_cl)**2/2/sigma_cl**2) for r in r_j]\n",
    "\n",
    "        p_j = np.array([p_ji[j, i] for j in range(p_ji.shape[0])], dtype=float)\n",
    "        k_j = np.array([k_ji[j, i] for j in range(k_ji.shape[0])], dtype=int)\n",
    "\n",
    "        # if np.isnan(p_j).any():\n",
    "        #     continue\n",
    "\n",
    "        if old_computation:\n",
    "            eps_i = np.asarray([k_j[j].reshape(-1, 1)*eps_j[j] * factor[j] for j in range(len(k_j))])\n",
    "            kap_i = np.asarray([k_j[j].reshape(-1, 1)*kap_j[j] * factor[j] for j in range(len(k_j))])\n",
    "        elif incorrect_computation:\n",
    "            eps_i = np.asarray([k_j[j].reshape(-1, 1)*eps_j[j]/dv * factor[j] for j in range(len(k_j))])\n",
    "            kap_i = np.asarray([k_j[j].reshape(-1, 1)*kap_j[j]/dv * factor[j] for j in range(len(k_j))])\n",
    "        else:\n",
    "            eps_i = np.asarray([k_j[j].reshape(-1, 1)*eps_j[j] * factor[j] for j in range(len(k_j))])\n",
    "            kap_i = np.asarray([k_j[j].reshape(-1, 1)*kap_j[j] * factor[j] for j in range(len(k_j))])\n",
    "\n",
    "        if suggested_fix:\n",
    "            # eps_ens[-1 = np.sum(eps_i, axis=0)\n",
    "            eps_ens.append(np.sum(eps_i, axis=0))\n",
    "            # kap_ens[i] = np.sum(kap_i, axis=0)\n",
    "            kap_ens.append(np.sum(kap_i, axis=0))\n",
    "        elif test_opacity:\n",
    "            kap_ens += ((p_j.prod(0)/p_j.prod(0).sum()).reshape(-1, 1)*np.sum(kap_i, axis=0)).sum(0)\n",
    "        else:\n",
    "            eps_ens += (p_j.prod(0).reshape(-1, 1)*np.sum(eps_i, axis=0)).sum(0)\n",
    "            kap_ens += -np.log(((p_j.prod(0)/p_j.prod(0).sum()).reshape(-1, 1)*np.exp(-np.sum(kap_i, axis=0)*ds)).sum(0))/ds\n",
    "    \n",
    "    if suggested_fix:\n",
    "        intensity = np.zeros_like(v_i)\n",
    "        optical_depth = np.zeros_like(v_i)\n",
    "        if debug:\n",
    "            plt.plot(np.asarray([e.sum(0) for e in eps_ens]))\n",
    "            plt.plot(np.asarray([k.sum(0) for k in kap_ens]))\n",
    "            print(kap_ens)\n",
    "        for i, v_cl in enumerate(v_i):\n",
    "            i_nan = kap_ens[i] == 0  #to prevent division by 0\n",
    "            intensity_comb = copy(eps_ens[i])\n",
    "            # print(\"opacity i:\", kap_ens[i])\n",
    "            # print(\"emissivity i:\", eps_ens[i])\n",
    "            # print(\"probability i:\", p_j)\n",
    "            # print(intensity_comb)\n",
    "            intensity_comb[~i_nan] = (intensity_comb[~i_nan]/kap_ens[i][~i_nan]*ds * (1-np.exp(-kap_ens[i][~i_nan]*ds)))\n",
    "            p_j = np.array([p_ji[j, i] for j in range(p_ji.shape[0])], dtype=float)\n",
    "            intensity[i] = ((p_j.prod(0)/p_j.prod(0).sum()).reshape(-1, 1) \n",
    "                            * intensity_comb).sum(0)\n",
    "            optical_depth[i] = -np.log(((p_j.prod(0)/p_j.prod(0).sum()).reshape(-1, 1) \n",
    "                                                      * np.exp(-kap_ens[i]*ds)).sum())\n",
    "            # print(optical_depth[i])\n",
    "            # print()\n",
    "        if kind == 'gaussian':\n",
    "            emissivity = intensity * optical_depth/ds / (1-np.exp(-optical_depth))\n",
    "            p_fit = curve_fit(two_gaussians, v_i, np.hstack((emissivity, optical_depth)), [1, 1, sigma_ens_tot])[0]\n",
    "            p_eps = curve_fit(gaussian, v_i, emissivity, [1, sigma_ens_tot])[0]\n",
    "            p_tau = curve_fit(gaussian, v_i, optical_depth, [1, sigma_ens_tot])[0]\n",
    "            sig_avg = np.linalg.norm([p_eps[1], p_tau[1]])/np.sqrt(2)\n",
    "            print('average sigma={:.4f}, fully-fitted sigma={:.4f}'.format(sig_avg, p_fit[2]))\n",
    "            eps_fit = gaussian(v_i, p_fit[0], p_fit[2])\n",
    "            tau_fit = gaussian(v_i, p_fit[1], p_fit[2])\n",
    "            i_nan = tau_fit == 0\n",
    "            int_fit = copy(eps_fit)\n",
    "            int_fit[~i_nan] = eps_fit[~i_nan] / tau_fit[~i_nan]*ds * (1-np.exp(-tau_fit[~i_nan]))\n",
    "            if plotfit:\n",
    "                print('intensity fit:', curve_fit(gaussian, v_i, intensity, [1, sigma_ens_tot])[0])\n",
    "                print('optical depth fit: a={:.4f} sigma={:.4f}'.format(p_fit[1], p_fit[2]))\n",
    "                print('emissivity fit: a={:.4f} sigma={:.4f}'.format(p_fit[0], p_fit[2]))\n",
    "                plt.figure()\n",
    "                plt.plot(v_i, emissivity, **calculated_kwargs)\n",
    "                plt.plot(v_i, eps_fit, **fitted_kwargs)\n",
    "                plt.title('emissivity')\n",
    "                plt.figure()\n",
    "                plt.plot(v_i, optical_depth, **calculated_kwargs)\n",
    "                plt.plot(v_i, tau_fit, **fitted_kwargs)\n",
    "                plt.title('optical depth')\n",
    "                plt.figure()\n",
    "                plt.plot(v_i, intensity, **calculated_kwargs)\n",
    "                plt.plot(v_i, int_fit, **fitted_kwargs)\n",
    "                plt.title('intensity')\n",
    "                plt.figure()\n",
    "                plt.plot(v_i, emissivity/optical_depth, **calculated_kwargs)\n",
    "                # plt.plot(v_i, eps_fit/tau_fit, **fitted_kwargs)\n",
    "                plt.title('ratio')\n",
    "            if linearfit:\n",
    "                fn_int = interp1d(v_i, int_fit, kind='slinear', fill_value='extrapolate')\n",
    "                fn_tau = interp1d(v_i, tau_fit, kind='slinear', fill_value='extrapolate')\n",
    "                intensity_fit = fn_int(v_obs_range)\n",
    "                optical_depth_fit = fn_tau(v_obs_range)\n",
    "            else:\n",
    "                emissivity_fit = gaussian(v_obs_range, p_eps[0], sig_avg)\n",
    "                optical_depth_fit = gaussian(v_obs_range, p_tau[0], sig_avg)\n",
    "                i_nan = optical_depth_fit == 0\n",
    "                intensity_fit = copy(emissivity_fit)\n",
    "                intensity_fit[~i_nan] = emissivity_fit[~i_nan] / optical_depth_fit[~i_nan]*ds * (1-np.exp(-optical_depth_fit[~i_nan]))\n",
    "        else:\n",
    "            fn_int = interp1d(v_i, intensity, kind=kind, fill_value='extrapolate')\n",
    "            fn_tau = interp1d(v_i, optical_depth, kind=kind, fill_value='extrapolate')\n",
    "            intensity_fit = fn_int(v_obs_range)\n",
    "            optical_depth_fit = fn_tau(v_obs_range)\n",
    "        if debug:\n",
    "            print(intensity)\n",
    "            print(optical_depth)\n",
    "        return intensity_fit, optical_depth_fit, v_obs_range\n",
    "    else:\n",
    "        intensity = np.nan_to_num(eps_ens/kap_ens * (1-np.exp(-kap_ens*ds)))\n",
    "        optical_depth = kap_ens * ds\n",
    "        return intensity, optical_depth, v_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90187e85-6584-4565-8947-9d16041bf4d5",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Probabilistic emission $\\left( \\left<\\epsilon\\right>_{vox} \\ , \\ \\left<\\kappa\\right>_{vox} \\ , \\ \\left<I\\right>_{vox} \\right)$ plotting function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7d4527-ceea-4dad-97ff-bc351872e2bb",
   "metadata": {},
   "source": [
    "Function to calculate and plot the probabilistic estimation of the voxel-averaged intensity and optical depth. Since the calculation is handled by `calculate_emission`, the contributions at each internal velocity of the ensemble are not shown.\n",
    "\n",
    "The final calculated integrated intensity in also printed.\n",
    "\n",
    " - `v_i`: kwarg for the internal velocity array. Must be of type ndarray, otherwise the array is created (errors still exist in this). The default value is None.\n",
    " - `v_obs`: kwarg for the observed velocity array. Must be of type ndarray, otherwise the array of size $1000$ is created spanning the interval $\\left[ -10, 10 \\right] \\frac{km}{s}$. The default value is None.\n",
    " - `n_v`: kwarg to adjust the step size in the internal velocity grid, which is the minimum of $\\left( \\frac{\\sigma_{ens}}{n_v}, \\frac{\\sigma_{cl}}{n_v} \\right)$. The default is defined in the beginning of the notebook.\n",
    " - `suggested_fix`: flag to set whether the original calculation of $\\Delta N_j$ is returned or the suggested improvement of $\\frac{dN_j}{dv}$. The default is defined in the beginning of the notebook.\n",
    " - `kind`: kwarg to set the pass to the interpolation function. This can be *gaussian*, *linear*, *nearest*, *nearest-up*, *zero*, *slinear*, *quadratic*, *cubic*, *previous*, or *next*. 'gaussian' fits a gaussian to the emissivity and optical depth using `scipy.optimize.curve_fit` and the widths are averaged, while the others are passed to `scipy.interpolate.interp1d`. The default is *slinear*.\n",
    " - `approx`: kwarg to calculate the approximate emission.\n",
    " - `poisson`: kwarg passed to `probability` to specify if the Poisson distribution should be used over the binomial distribution to calculate the combination probabilities. The default is False, so the binomial distribution is used.\n",
    " - `plotfit`: if True and `kind`='gaussian', the gaussian-fitted emissivity, optical depth, intensity, and source function are calculated with `v_i` and plotted.\n",
    " - `linearfit`: if True and `kind`='gaussian', the gaussian-fitted emissivity and optical depth are interpolated at `v_obs` .\n",
    " - `residual`: if True, plot the source function as a residual from its maximum. The default is False.\n",
    " - `zoom`: if a float $> 0$ and residual=True, set the maximum of of the residual plot. The default is 0 (maximum automatically set).\n",
    " - `debug`: print additional debugging statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d424502-a708-43f3-901e-8d0206f002ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_probabilistic_emission(v_i=None, n_v=n_v, nmax=nmax, suggested_fix=suggested_fix, kind='slinear', approx=approx, poisson=False, \n",
    "                                plotfit=False, linearfit=True, residual=False, zoom=0, debug=False):\n",
    "\n",
    "\n",
    "    # Determine most probable combination\n",
    "    p_j = np.asarray([np.pi*r**2/ds**2 for r in r_j])\n",
    "    x = [np.arange(0, n+1) for n in n_j]\n",
    "    x_mesh = np.asarray([comb.flatten() for comb in np.meshgrid(*x)])\n",
    "    y = [stats.binom.pmf(x_mesh[j], n_j[j], p_j[j]) for j in range(len(n_j))]\n",
    "    prob = np.prod(y, axis=0)\n",
    "    if prob[-1] == prob.max() or (x_mesh[:, prob.argmax()] < 2).all():\n",
    "        n_ens = p_j * x_mesh[:, prob.argmax()]\n",
    "    else:\n",
    "        n_ens = x_mesh[:, prob.argmax()]\n",
    "\n",
    "\n",
    "    if suggested_fix:\n",
    "        intensity_ens, optical_depth_ens, v_obs_range = calculate_emission(v_i=v_i, n_v=n_v, nmax=nmax, suggested_fix=suggested_fix, kind=kind, approx=approx, poisson=poisson, plotfit=plotfit, linearfit=linearfit, debug=debug)\n",
    "        emissivity_ens = copy(intensity_ens)\n",
    "        i_nan = np.isnan(optical_depth_ens) | (optical_depth_ens == 0)\n",
    "        emissivity_ens[~i_nan] *= optical_depth_ens[~i_nan] / ds / (1-np.exp(-optical_depth_ens[~i_nan]))\n",
    "        opacity_ens = optical_depth_ens/ds\n",
    "    else:\n",
    "        intensity_ens, optical_depth_ens, v_obs = calculate_emission(v_i=v_i, n_v=n_v, nmax=nmax, suggested_fix=suggested_fix, kind=kind, approx=approx, poisson=poisson, debug=debug)\n",
    "        eps_ens = np.nan_to_num(intensity_ens/ds * optical_depth_ens / (1-np.exp(-optical_depth_ens)), nan=0, posinf=0)\n",
    "        kap_ens = np.nan_to_num(optical_depth_ens) / ds\n",
    "\n",
    "    \n",
    "#     # Emissivity\n",
    "    if suggested_fix:\n",
    "        eps = np.sum([n_ens[j]*eps_j[j] * np.sqrt(2*np.pi*sigma_cl**2) / np.sqrt(2*np.pi*sigma_ens_tot**2) * np.exp(-(v_vox-v_obs_range)**2/2/sigma_ens_tot**2) for j in range(len(n_j))], axis=0)\n",
    "    else:\n",
    "        eps = np.sum([n_ens[j]*eps_j[j] * np.sqrt(2*np.pi*sigma_cl**2) / np.sqrt(2*np.pi*sigma_ens_tot**2) * np.exp(-(v_vox-v_obs)**2/2/sigma_ens_tot**2) for j in range(len(n_j))], axis=0)\n",
    "    \n",
    "    if plot_all:\n",
    "        fig_eps, ax_eps = plt.subplots(1, 1, figsize=figsize)\n",
    "        \n",
    "    if plot_all:\n",
    "        if suggested_fix:\n",
    "            if approx:\n",
    "                ax_eps.plot(v_obs_range, eps, **approximated_kwargs)\n",
    "        else:\n",
    "            if approx:\n",
    "                ax_eps.plot(v_obs, eps, **approximated_kwargs)\n",
    "            ax_eps.plot(v_obs, eps_ens, **calculated_kwargs)\n",
    "            ax_eps.legend(fontsize=fontsize*legend_factor)\n",
    "        ax_eps.set_xlabel(r'$v_{obs} \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "        ax_eps.set_ylabel(r'$\\epsilon \\ \\left( \\frac{K}{pc} \\right)$', fontsize=fontsize)\n",
    "\n",
    "    \n",
    "#     # Opacity\n",
    "    if suggested_fix:\n",
    "        kap = np.sum([n_ens[j]*kap_j[j] * np.sqrt(2*np.pi*sigma_cl**2) / np.sqrt(2*np.pi*sigma_ens_tot**2) * np.exp(-(v_vox-v_obs_range)**2/2/sigma_ens_tot**2) for j in range(len(n_j))], axis=0)\n",
    "    else:\n",
    "        kap = np.sum([n_ens[j]*kap_j[j] * np.sqrt(2*np.pi*sigma_cl**2) / np.sqrt(2*np.pi*sigma_ens_tot**2) * np.exp(-(v_vox-v_obs)**2/2/sigma_ens_tot**2) for j in range(len(n_j))], axis=0)\n",
    "    \n",
    "    if plot_all:\n",
    "        fig_kap, ax_kap = plt.subplots(1, 1, figsize=figsize)\n",
    "    \n",
    "    if plot_all:\n",
    "        if suggested_fix:\n",
    "            if approx:\n",
    "                ax_kap.plot(v_obs_range, kap, **approximated_kwargs)\n",
    "        else:\n",
    "            if approx:\n",
    "                ax_kap.plot(v_obs, kap, **approximated_kwargs)\n",
    "            ax_kap.plot(v_obs, kap_ens, **calculated_kwargs)\n",
    "            ax_kap.legend(fontsize=fontsize*legend_factor)\n",
    "        ax_kap.set_xlabel(r'$v_{obs} \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "        ax_kap.set_ylabel(r'$\\kappa \\ \\left( \\frac{1}{pc} \\right)$', fontsize=fontsize)\n",
    "\n",
    "    \n",
    "    # Intensity\n",
    "    fig_int, ax_int = plt.subplots(1, 1, figsize=figsize)\n",
    "    if suggested_fix:\n",
    "        intensity = np.nan_to_num(eps/kap/ds * (1-np.exp(-kap*ds)))\n",
    "        if approx:\n",
    "                ax_int.plot(v_obs_range, intensity, **approximated_kwargs)\n",
    "        ax_eps.plot(v_obs_range, emissivity_ens, **calculated_kwargs)\n",
    "        # ax_eps.plot(v_obs_range, emissivity_fit, **fitted_kwargs)\n",
    "        ax_kap.plot(v_obs_range, opacity_ens, **calculated_kwargs)\n",
    "        # ax_kap.plot(v_obs_range, opacity_fit, **fitted_kwargs)\n",
    "        ax_int.plot(v_obs_range, intensity_ens, **calculated_kwargs)\n",
    "        # ax_int.plot(v_obs_range, intensity_fit, **fitted_kwargs)\n",
    "        ax_eps.legend(fontsize=fontsize*legend_factor)\n",
    "        ax_kap.legend(fontsize=fontsize*legend_factor)\n",
    "    \n",
    "    else:\n",
    "        if approx:\n",
    "            intensity = np.nan_to_num(eps/kap * (1-np.exp(-kap*ds)))\n",
    "            ax_int.plot(v_obs, intensity, **approximated_kwargs)\n",
    "        ax_int.plot(v_obs, intensity_ens, **calculated_kwargs)\n",
    "    \n",
    "    ax_int.set_xlabel(r'$v_{obs} \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "    ax_int.set_ylabel(r'$\\left< I \\right>_{ens} \\ \\left( K \\right)$', fontsize=fontsize)\n",
    "    ax_int.legend(fontsize=fontsize*legend_factor)\n",
    "\n",
    "    \n",
    "    # Integrated intensity\n",
    "    if suggested_fix:\n",
    "        if approx:\n",
    "            print('         Integrated intensity (no discretisation):', np.trapz(intensity, v_obs_range))\n",
    "        print('       Integrated intensity (with discretisation):', np.trapz(intensity_ens, v_obs_range))\n",
    "    else:\n",
    "        if approx:\n",
    "            print('Integrated intensity (no discretisation):', np.trapz(intensity, v_obs))\n",
    "        print('Integrated intensity (with discretisation):', np.trapz(intensity_ens, v_obs))\n",
    "    \n",
    "    \n",
    "    # RT equation factor\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    if suggested_fix:\n",
    "        if approx:\n",
    "            ax.plot(v_obs_range, eps/kap, **approximated_kwargs)\n",
    "        max_ens = (emissivity_ens/opacity_ens).max()\n",
    "        if residual:\n",
    "            ax.scatter(v_obs_range, max_ens - emissivity_ens/opacity_ens, **calculated_kwargs, marker='+', s=25)\n",
    "            ax.set_ylabel(r'$res \\left( \\frac{\\epsilon}{\\kappa} \\right) \\ \\left( K \\right)$', fontsize=fontsize)\n",
    "            if zoom:\n",
    "                ax.set_ylim((0, zoom))\n",
    "        else:\n",
    "            ax.plot(v_obs_range, emissivity_ens/opacity_ens, **calculated_kwargs)\n",
    "            ax.set_ylabel(r'$\\frac{\\epsilon}{\\kappa} \\ \\left( K \\right)$', fontsize=fontsize)\n",
    "    else:\n",
    "        if approx:\n",
    "            ax.plot(v_obs, eps/kap, **approximated_kwargs)\n",
    "        max_ens = (eps_ens/kap_ens).max()\n",
    "        ax.scatter(v_obs, eps_ens/kap_ens - avg_ens, **calculated_kwargs)\n",
    "        ax.set_ylabel(r'$\\frac{\\epsilon}{\\kappa} \\ \\left( K \\right)$', fontsize=fontsize)\n",
    "    ax.set_xlabel(r'$v_{obs} \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "    ax.legend(fontsize=fontsize*legend_factor)\n",
    "    \n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec03733-fdf0-414b-bf52-4bb0a903de3b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf8ef57-bb41-481f-9e04-1f8930b29c5f",
   "metadata": {},
   "source": [
    "A simple definition for an un-normalised gaussian function. Ideal for fitting.\n",
    "\n",
    " - `x`: independant variable array.\n",
    " - `a`: amplitude of curve.\n",
    " - `sigma`: width of curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ad92a-7915-43e7-a4f7-88fc1856d4c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gaussian(x, a, sigma):\n",
    "    return a * np.exp(-x**2 / (2*sigma**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8931883-56f7-4460-b5d7-be910c31f11c",
   "metadata": {},
   "source": [
    "A function to fit two gaussians simultaneously. The result will be horizontally stacked, so the fitting data will need to be in the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189aa8aa-2763-4148-ad31-c457b49f1d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_gaussians(x, a1, a2, sigma):\n",
    "    g1 = gaussian(x, a1, sigma)\n",
    "    g2 = gaussian(x, a2, sigma)\n",
    "    return np.hstack((g1, g2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c345b6c9-8d35-4145-8e80-32440bf0e1c5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Discretisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a632f42-c558-4752-b293-ab8a72c87607",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Examining the original discretisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b648c254-b816-4351-ab21-f09cd823516b",
   "metadata": {},
   "source": [
    "In the work of Andree-Labsch et al. (2017), the spacing of the clumps in the ensemble was the same as the observing velocities, namely $\\delta v = 1 \\frac{km}{s}$. Since each clump had $\\sigma_{cl} \\approx 0.71 \\frac{km}{s}$, this discretisation was reasonable (though still not correct). In the current version of `kosmatau3d`, an internal velocity grid is created for the clumps in the ensemble with a velocity spacing of $\\delta v = \\mathrm{min} \\left( \\frac{\\sigma_{ens}}{n_{velocity}}, \\frac{\\sigma_{cl}}{n_{velocity}} \\right)$ with $n_{velocity} = 3$ being a reasonable approximation. For $\\sigma_{ens},\\sigma_{cl} < n_{velocity} \\times 1 \\frac{km}{s}$, this discretisation approximation gets worse and the resulting emissivity and opacity will be over-estimated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b809d51-bbdf-4565-a788-8cf380427474",
   "metadata": {},
   "source": [
    "The final intensity is computed using the radiative transfer equation for a voxel with side length $\\Delta s$:\n",
    "\n",
    "$$\n",
    "I \\left( v_{obs} \\right) = \\frac{\\epsilon \\left( v_{obs} \\right)}{\\kappa \\left( v_{obs} \\right)} \\ \\left( 1 - e^{- \\kappa \\left( v_{obs} \\right) \\Delta s} \\right)\n",
    "$$\n",
    "\n",
    "The initial factor should equate to a constant provided the emissivity and opacity are Gaussian profiles as expected. One issue with the single-voxel model is that this factor is not equating to a constant with $v_{obs}$, so we will examine it the final two plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60cd923-d5e4-4bfc-a1a7-5aa4eb33d2d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v_i = np.linspace(-10, 10, num=11)\n",
    "\n",
    "plot_clump_number(v_i=v_i, n_v=None, suggested_fix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8edfb46-b955-4734-934d-d34d89f522c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v_i = np.linspace(-10, 10, num=21)\n",
    "\n",
    "plot_clumpy_emission(v_i=v_i, n_v=None, suggested_fix=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333e5b29-ae05-456f-90db-1e32065d6e4a",
   "metadata": {},
   "source": [
    "So this discretisation appears to be appropriate for estimating the overall structure of the emission."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51730892-f11d-4093-bd5d-aa269027b7e7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Using a finer discretisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ab5544-e62a-419b-b405-c3933779f245",
   "metadata": {},
   "source": [
    "Now we may us the same functions, but this time we specify that internal velocity grid that should be evalvulated automatically with our given value of $n_{velocity}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51c82f6-c989-41dc-bc70-ae79de492763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v_i = np.linspace(-10, 10, num=500)\n",
    "\n",
    "plot_clump_number(v_i=v_i, suggested_fix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e710b51-dcac-4d48-9976-17068c903065",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_clumpy_emission(v_i=v_i, suggested_fix=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3f3882-a2ca-40c2-b0f7-3a3c9c3855ba",
   "metadata": {},
   "source": [
    "Judging by the calculated $\\varpi \\equiv \\int I dv$, this method performs with the same accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc76013e-76e6-4d29-adf2-4e2364581a31",
   "metadata": {},
   "source": [
    "We also see that these approximations of the ensemble intensity both follow the same Gaussian distribution, since the factor of $\\frac{\\epsilon_{ens}}{\\kappa_{ens}}$ is constant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ee2ed8-dee8-4581-aee9-1616c1af3d7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Probabilistic approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0882785f-8933-433c-ad11-ac45019bd9d5",
   "metadata": {},
   "source": [
    "Thus-far we have merely considered how the discretisation affects the intensity of the ensemble. The full implementation of `kosmatau3d` uses a probabilistic approach to calculate the likelihood of having a given combination $k_{j,i}$ of clumps in your line-of-sight. The probability of each clump depends on its projected area ($\\pi R_{cl}^2$) compared with the area of one face of the voxel ($\\Delta s$).\n",
    "\n",
    "$$\n",
    "p_{j,i} = \\binom{\\Delta N_{j,i}}{k_{j,i}} \\ p_j^{k_{j,i}} \\ \\left( 1 - p_j \\right)^{\\Delta N_{j,i} - k_{j,i}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f46a13d-10f7-4b09-83cd-7cfd92588e9a",
   "metadata": {},
   "source": [
    "This probability is then applied to the emissivity and opacity in different ways due to how they enter into the radiative transfer equation. For each systematic velocity,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\left< \\epsilon \\right>_{i} =& \\sum_{k} \\left( \\prod_{j} p_{j,i} \\right) \\left( \\sum_{j} k_{j,i} \\epsilon_{j} \\right) \\ , \\\\\n",
    "\\left< \\kappa \\right>_{i} =& - \\mathrm{log} \\left[ \\sum_{k} \\left( \\prod_{j} p_{j,i} \\right) \\mathrm{exp} \\left( - \\sum_{j} k_{j,i} \\kappa_{j} \\Delta s \\right) \\right] \\ \\div \\ \\Delta s \\ .\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28100694-71c5-4161-a751-f4d2f522cdfa",
   "metadata": {},
   "source": [
    "The voxel-averaged values are thus simply,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\left< \\epsilon \\right>_{vox} \\left( v_{obs} \\right) =& \\sum_{i} \\left< \\epsilon \\right>_{i} \\left( v_{obs} \\right) \\ , \\\\\n",
    "\\left< \\kappa \\right>_{vox} \\left( v_{obs} \\right) =& \\sum_{i} \\left< \\kappa \\right>_{i} \\left( v_{obs} \\right) \\ .\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f03b9c-62b7-406a-8341-7309b3d8f066",
   "metadata": {},
   "source": [
    "In this manner the emissivity and opacity are decoupled and independant. There is an issue, though, since the sum over $v_i$ should occur before the probability of each combination is applied. Also, the probability should act on the intensity rather than the emissivity using $I_{\\nu, i} = \\frac{\\epsilon_{\\nu, i}}{\\kappa_{\\nu, i}} \\bigg( 1 - exp \\Big(- \\kappa_{\\nu, i} \\Delta s \\Big) \\bigg)$. For these reasons the calculation should be corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3625d836-4065-4cf7-ab2b-5430722d17ec",
   "metadata": {},
   "source": [
    "To avoid too many unnecessary loops, the suggestion is to calculate the clump number independant of $v_{i}$.\n",
    "\n",
    " > Assuming $\\delta v_i << \\sigma_{ens}$, then,\n",
    " >\n",
    " > $$\n",
    "   \\begin{align}\n",
    "   \\frac{dN_{j,i}}{dv_i} =& \\ {\\lim_{\\delta v_i \\to 0}} \\left( \\frac{\\Delta N_{j,i}}{\\delta v_i} \\right) \\ , \\\\\n",
    "   =& \\ \\frac{N_j}{\\sqrt{2 \\pi \\sigma_{ens}^2}} exp \\Big( - \\frac{(v_i-v_{vox})^2}{2 \\sigma_{ens}^2} \\Big) \\ , \\\\\n",
    "   =& \\ \\mathrm{constant}.\n",
    "   \\end{align}\n",
    "   $$\n",
    " > \n",
    " > Then for each observing velocity the sum over the contribution from each clump will be,\n",
    " > \n",
    " > $$\n",
    "   \\begin{align}\n",
    "   N_{j,i} =& \\sum_i exp \\Big( - \\frac{(v_i-v_{obs})^2}{2\\sigma_{cl}^2} \\Big) \\ \\Delta N_{j,i} \\ , \\\\\n",
    "   =& \\int_{-\\inf}^\\inf dv_i exp \\Big( - \\frac{(v_i-v_{obs})^2}{2\\sigma_{cl}^2} \\Big) \\ \\frac{dN_{j,i}}{dv_i} \\ , \\\\\n",
    "   =& \\sqrt{2 \\pi \\sigma_{cl}^2} \\ \\frac{dN_{j,i}}{dv_i} \\ , \\\\\n",
    "   =& N_j \\frac{\\sigma_{cl}}{\\sigma_{ens}} exp \\Big( - \\frac{(v_i-v_{vox})^2}{2 \\sigma_{ens}^2} \\Big) \\ .\n",
    "   \\end{align}\n",
    "   $$\n",
    " >\n",
    " > Since we are now including the contribution from clumps at other velocities in the definition of $N_{j,i}$, the velocity distribution of the ensemble is actually the total velocity dispersion $\\sigma_{ens,eff}$. Below we examine the applicability of this assumption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17cbb08-c75c-49e0-a8b4-e8d169b83c46",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Isolate the scope of this cell\n",
    "def test_dist():\n",
    "    \n",
    "    # Define dispersion variables unique to this cell\n",
    "    sigma_cl_test = copy(sigma_cl)\n",
    "    sigma_ens_test = 1\n",
    "    sigma_ens_eff_test = np.sqrt(sigma_ens_test**2 + sigma_cl**2)\n",
    "\n",
    "    # Velocity arrays\n",
    "    v_obs = np.linspace(-10, 10, num=1000)\n",
    "    v_i = np.linspace(-10, 10, num=2001).reshape(-1, 1)\n",
    "    dv_i = v_i[1]-v_i[0]\n",
    "\n",
    "    # Calculate N_j,i using various approximations \n",
    "    y1 = (1/np.sqrt(2*np.pi*sigma_ens_test**2) * np.exp(-(v_i-0)**2/2/sigma_ens_test**2) * np.exp(-(v_i-v_obs.reshape(1, -1))**2/2/sigma_cl_test**2)).sum(0) * dv_i\n",
    "    y2 = (np.sqrt(2*np.pi*sigma_cl_test**2)/np.sqrt(2*np.pi*sigma_ens_eff_test**2) * np.exp(-(0-v_obs)**2/2/sigma_ens_eff_test**2))\n",
    "    mu_test = (sigma_ens_test**2*v_obs/(sigma_ens_test**2-sigma_cl_test**2)).reshape(1, -1)\n",
    "    sigma_test = (sigma_ens_test**2*sigma_cl_test**2)/(sigma_ens_test**2+sigma_cl_test**2)\n",
    "    # y3 = (1/np.sqrt(2*np.pi*sigma_test**2) * np.exp(-(v_i-mu_test)**2/(2*sigma_test**2))).sum(0) * dv_i\n",
    "    y3 = (np.sqrt(2*np.pi*sigma_cl_test**2)/np.sqrt(2*np.pi*sigma_ens_test**2) * np.exp(-(v_obs-0)**2/(2*sigma_ens_test**2)))\n",
    "\n",
    "    # Plot the approximations\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.plot(v_obs, y2, **approximated_kwargs)\n",
    "    plt.plot(v_obs, y1, **calculated_kwargs)\n",
    "    plt.plot(v_obs, y3, color=\"xkcd:maroon\", label=r\"test using $\\sigma_{ens}$\")\n",
    "    plt.legend()\n",
    "    \n",
    "    # Print the area under each curve\n",
    "    print(\"  Calculated curve area:\", np.trapz(y1, v_obs))\n",
    "    print(\"Approximated curve area:\", np.trapz(y2, v_obs))\n",
    "    print(\"      Formal curve area:\", np.trapz(y3, v_obs))\n",
    "    \n",
    "    return\n",
    "\n",
    "test_dist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51202516-5137-4eea-9fc8-8c6a135d3687",
   "metadata": {},
   "source": [
    "As seen above, the use of $\\sigma_{ens_{eff}}$ fits better than $\\sigma_{ens}$, though the area under each curve is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73841417-df5d-4b33-9e45-bc2b0df39c07",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "md(r'Now we wish to apply this procedure to our previous example. Let us assume our clump has a radius of $R_{cl} =$'\n",
    "   + r'{} $pc$.'.format(r_j))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c305f45e-ef06-4834-803e-8efc94e21c91",
   "metadata": {
    "tags": []
   },
   "source": [
    "### With a coarse discretisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660c193f-839e-4f28-b17c-f15a6eda52f6",
   "metadata": {},
   "source": [
    "First we examine how the original discretisation handles a dense voxel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d88d0e-a007-4815-a4bc-fa712c830207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v_i = np.linspace(-10, 10, num=11)\n",
    "\n",
    "plot_probabilistic_dNji(v_i=v_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d238628-74ad-48c1-a397-8ba68525b3cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_j = [10]\n",
    "# nmax = 0\n",
    "v_i = np.linspace(-10, 10, num=11)\n",
    "\n",
    "plot_probabilistic_emission(v_i=v_i, n_v=None, suggested_fix=True, kind='gaussian', poisson=False, plotfit=False, linearfit=False, residual=False) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2fded3-4a7e-4767-be8c-394e841c6a77",
   "metadata": {},
   "source": [
    "As it can be seen, there are some discontinuous features in the wings. So far as I can tell from the overall development of `kosmatau3d`, this is due to the probabilistic approach; each discontinuity is located where the there is a difference in the number of combinations considered. The initial fraction in the radiative transfer equation, $S = \\left( \\frac{\\epsilon}{\\kappa} \\right)$, should cancel out any underlying structure and equate to a constant.\n",
    "\n",
    "Now in the probabilistic discretisation, $\\left< \\epsilon \\right>_{ens}$ and $\\left< \\kappa \\right>_{ens}$ are not perfect Gaussians but follow a similar structure. For that reason we are mainly concerned with the smoothness of this initial fraction. When it has non-constant features, the resulting intensity $\\left< I \\right>_{vox} \\left( v_{obs} \\right)$ will also have these non-constant features.\n",
    "\n",
    "Plots of this fraction can be seen in the final plot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6251b6b2-bb26-45e9-96cb-b68ca4374a9b",
   "metadata": {},
   "source": [
    "### Using a finer discretisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb659796-41df-4e58-abbd-6b222c7f1d05",
   "metadata": {},
   "source": [
    "Using a higher velocity resolution in the model should highlight some features that result from a numerical artefact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e403f1-2047-4eb2-bef3-e52f16721df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10)\n",
    "fn = interp1d(x, np.sin(x))\n",
    "plt.plot(x, fn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9152864e-a2ef-4cd9-af8f-eab950045d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "with open('dilled_obj', 'wb') as file:\n",
    "    dill.dump(fn, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23d169-e73b-4bb5-a8db-d4fa7892a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dilled_obj', 'rb') as file:\n",
    "    fn = dill.load(file)\n",
    "x = np.linspace(0, 8, num=100)\n",
    "plt.plot(x, fn(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999af74-7f04-4b5a-9e85-7e9f46b02a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "v_i = np.linspace(-10, 10, num=100)\n",
    "\n",
    "plot_probabilistic_dNji(v_i=v_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef61d45-08a3-4e6b-a955-3f2783b9007a",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_i = np.linspace(-10, 10, num=100)\n",
    "\n",
    "plot_probabilistic_dNji(v_i=v_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f9910-b894-4dc9-80b6-6c50f1e7a2fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_j = [10]\n",
    "nmax = 1\n",
    "v_i = np.linspace(-10, 10, num=100)\n",
    "\n",
    "plot_probabilistic_emission(v_i=v_i, n_v=None, nmax=nmax, suggested_fix=True, kind='slinear', poisson=False, plotfit=True, linearfit=False, residual=False, zoom=0) ;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3686d5ff-82e7-4a44-b312-109a7ecbfe99",
   "metadata": {},
   "source": [
    "There are still wavy features when `suggested_fix` is False, which is seen also in the source function.\n",
    "\n",
    "It seems the wavy features are no longer an issue when using `suggested_fix`. However, the factor of $\\frac{\\left< \\epsilon_\\nu \\right>_{vox}}{\\left< \\kappa_\\nu \\right>_{vox}}$ used to judge the validity of the discrete clump calculation will not work for the raw calculation due to the use of $\\left< \\tau_\\nu \\right>_{vox}$ in deriving $\\left< \\epsilon_\\nu \\right>_{vox}$. Despite this, we can be sure of its validity of this calculation due to the theoretical derivation and limiting of initial assumptions. Specifying the *gaussian* method of interpolation will in fact fit a Gaussian to the emissivity and optical depth, so the souce function will in fact be flat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15208c-9d9c-41d3-80cf-8f4aeb260ea2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707a28d2-292e-4ada-8d6e-6333b1eb5c86",
   "metadata": {},
   "source": [
    "When not using the suggested calculation, the previous plots not only show that a smooth fraction will result in a smooth absorption feature, but also that $\\left< \\epsilon \\right>_{ens}$ and $\\left< \\kappa \\right>_{ens}$ follow different distributions. To approximate this in terms of a Gaussian, we will perform a fit to examine how much they differ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae8f77c-cbbe-4661-9924-6a25e752b9d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eps_eff(v, a, sigma_eff):\n",
    "    return np.sum([a * n_ens[cl]*eps_j[cl]/np.sqrt(2*np.pi*sigma_eff**2) * np.exp(-v**2/2/sigma_eff**2) for cl in range(len(n_ens))], axis=0)\n",
    "\n",
    "def kap_eff(v, a, sigma_eff):\n",
    "    return np.sum([a * n_ens[cl]*kap_j[cl]/np.sqrt(2*np.pi*sigma_eff**2) * np.exp(-v**2/2/sigma_eff**2) for cl in range(len(n_ens))], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54a1f28-198a-415d-a5c0-299242beafed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Only fit the emissivity and opacity when using the former calculation of the intensity\n",
    "if not suggested_fix:\n",
    "    \n",
    "    def fit_emission():\n",
    "    \n",
    "        a_eps, sigma_eps_eff = curve_fit(eps_eff, v_obs, eps_ens, [1, sigma_ens])[0]\n",
    "        a_kap, sigma_kap_eff = curve_fit(kap_eff, v_obs, kap_ens, [1, sigma_ens])[0]\n",
    "\n",
    "        print('fitted amplitudes:\\n{}\\n{}\\n'.format(a_eps, a_kap))\n",
    "        print('fitted dispersions:\\n{}\\n{}\\n'.format(sigma_eps_eff, sigma_kap_eff))\n",
    "\n",
    "        eps_fit = eps_eff(v_obs, a_eps, sigma_eps_eff)\n",
    "        kap_fit = kap_eff(v_obs, a_kap, sigma_kap_eff)\n",
    "\n",
    "        # Emissivity\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(v_obs, eps, c='xkcd:black', lw=3, label='approximated')\n",
    "        plt.plot(v_obs, eps_fit, c='xkcd:charcoal', lw=2, ls='-', label='fitted')\n",
    "        plt.plot(v_obs, eps_ens, c='xkcd:vomit', lw=2, ls='--', label='calculated')\n",
    "        plt.legend(fontsize=fontsize*legend_factor)\n",
    "        plt.title('Fitted emissivity', fontsize=fontsize)\n",
    "        plt.xlabel(r'$v_{obs} \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "        plt.ylabel(r'$\\left< \\epsilon \\right>_{ens} \\ \\left( \\frac{K}{pc} \\right)$', fontsize=fontsize)\n",
    "        \n",
    "        # Opacity\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(v_obs, kap, c='xkcd:black', lw=3, label='approximated')\n",
    "        plt.plot(v_obs, kap_fit, c='xkcd:charcoal', lw=2, ls='-', label='fitted')\n",
    "        plt.plot(v_obs, kap_ens, c='xkcd:vomit', lw=2, ls='--', label='calculated')\n",
    "        plt.legend(fontsize=fontsize*legend_factor)\n",
    "        plt.title('Fitted opacity', fontsize=fontsize)\n",
    "        plt.xlabel(r'$v_{obs} \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "        plt.ylabel(r'$\\left< \\kappa \\right>_{ens} \\ \\left( \\frac{1}{pc} \\right)$', fontsize=fontsize)\n",
    "        \n",
    "        # Ratio\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(v_obs, eps/kap, c='xkcd:black', lw=3, label='approximated')\n",
    "        plt.plot(v_obs, eps_fit/kap_fit, \n",
    "                 c='xkcd:charcoal', lw=2, ls='-', label='fitted')\n",
    "        plt.plot(v_obs, eps_ens/kap_ens, c='xkcd:vomit', lw=2, ls='--', label='calculated')\n",
    "        plt.legend(fontsize=fontsize*legend_factor)\n",
    "        plt.title('Fitted fraction', fontsize=fontsize)\n",
    "        plt.xlabel(r'$v_{obs} \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "        plt.ylabel(r'$\\frac{\\left< \\epsilon \\right>_{ens}}{\\left< \\kappa \\right>_{ens}} \\ \\left( K \\right)$', fontsize=fontsize)\n",
    "        \n",
    "        # Intensity\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(v_obs, eps/kap*(1-np.exp(-kap*ds)), c='xkcd:black', lw=3, label='approximated')\n",
    "        plt.plot(v_obs, eps_fit/kap_fit*(1-np.exp(-kap_fit*ds)), c='xkcd:charcoal', lw=2, ls='-', label='fitted')\n",
    "        plt.plot(v_obs, eps_ens/kap_ens*(1-np.exp(-kap_ens*ds)), c='xkcd:vomit', lw=2, ls='--', label='calculated')\n",
    "        plt.legend(fontsize=fontsize*legend_factor)\n",
    "        plt.title('Fitted Intensity', fontsize=fontsize)\n",
    "        plt.xlabel(r'$v_{obs} \\ \\left( \\frac{km}{s} \\right)$', fontsize=fontsize)\n",
    "        plt.ylabel(r'$\\left< I \\right>_{ens} \\ \\left( K \\right)$', fontsize=fontsize)\n",
    "        \n",
    "        return\n",
    "    \n",
    "    fit_emission()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cad7038-60d9-4529-9c01-2430c0dd503d",
   "metadata": {},
   "source": [
    "## Final remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d0089b-920c-441e-ad2c-5b3a8ad0d10b",
   "metadata": {},
   "source": [
    "When using the original calculations, it is clear that the probabilistic approach affects the behaviour of the emissivity and opacity with respect to observing velocity. Using a standard assumption that both the emissivity and the absorption follow the same Gaussian distribution with velocity dispersion $\\sigma_{ens, eff}$, their ratio will cause the Gaussian distributions to cancel and the result will be a value constant with respect to observing velocity. If we assume the emissivity and opacity follow two slightly different Gaussians (as in the fitted values), then the ratio will also have a Gaussian structure. What seems to be happening in the probabilistic approach is that the voxel-averaged emissivity follows a more strongly-peaked Gaussian than the voxel-averaged opacity near the center velocity, whereas they follow the same Gaussian distribution far away from the center velocity. The pseudo-Gaussian behaviour of these values appear to cause the steep edges in the wings of the intensity plot. The fitted emissivity and opacity are very close to the voxel-averaged values, but they are unable to capture these sharp wings.\n",
    "\n",
    "Another implementation suggestion is to remove the internal velocity grid entirely and use a modified $\\sigma_{ens}$ in the exponent (as demonstrated when `suggested_fix`=True) when calculating the number of clumps. It is sufficiently shown above that this effectively increases the number of clumps at each observing velocity and it works suitably-well for approximating the intensity of the voxel. While this does not suffer from the self-absorbtion numerical error of the original calculation and is much more computationally-efficient, it still has some intrinsic error from its implementation. There is a discontinuity introduced when the number of combinations increases due the probability. It can be shown above (by setting `kind`='gaussian' and `plotfit`=True) that the emissivity and optical depth curves are still mostly Gaussian, so this numerical artefact should not introduce a large error. Still, it is possible to fit a Gaussian function to remove this artefact. Another benefit of the newer calculation is that it does not require a dense internal velocity grid."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
